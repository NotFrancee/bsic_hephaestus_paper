{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Selection:\n",
    "    def __init__(self, start_date, end_date, \n",
    "                 method='pfa', q = None, explained_var= 0.95, \n",
    "                 diff_n_features = 2, verbose=False):\n",
    "       \n",
    "        if not isinstance(start_date, pd.Timestamp):\n",
    "            start_date = pd.to_datetime(start_date)\n",
    "        # Convert end_date to datetime if it's not already\n",
    "        if not isinstance(end_date, pd.Timestamp):\n",
    "            end_date = pd.to_datetime(end_date)\n",
    "        if method not in ['pca', 'pfa']:\n",
    "            raise Exception('Method must be either PCA or PFA')\n",
    "        #TODO check there is data for each stock in the selected period\n",
    "\n",
    "        self.method = method\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.diff_n_features = diff_n_features\n",
    "        self.q = q\n",
    "        \n",
    "        self.explained_var = explained_var\n",
    "\n",
    "        self.fitted = False\n",
    "\n",
    "        #For pca\n",
    "        self.pca = None\n",
    "        self.explained_variance = None\n",
    "        self.principal_components = None\n",
    "        self.reduced_data = None\n",
    "        \n",
    "        #For pfa\n",
    "        self.indices = None\n",
    "        self.features = None\n",
    "\n",
    "    def subset_stock_data(self, data):\n",
    "        # Check if 'Date' column exists in the dataframe\n",
    "        if 'Date' not in data.columns:\n",
    "            raise ValueError(\"DataFrame does not contain a 'Date' column.\")\n",
    "        \n",
    "        # Convert date columns to datetime if they are not already datetime objects\n",
    "        if not isinstance(data['Date'], pd.DatetimeIndex):\n",
    "            data['Date'] = pd.to_datetime(data['Date'])\n",
    "        \n",
    "        # Subset the dataframe based on date range\n",
    "        subset = data[(data['Date'] >= self.start_date) & (data['Date'] <= self.end_date)]\n",
    "        if self.verbose:\n",
    "            print('Succesfully subsetted data for selected timeframe.')\n",
    "        return subset\n",
    "        \n",
    "    def remove_non_numerical_columns(self, data):\n",
    "        # Check first 10 rows for numerical columns\n",
    "        first_10_rows = data.head(10)\n",
    "        non_numerical_columns = []\n",
    "\n",
    "        # Iterate through columns\n",
    "        for column in data.columns:\n",
    "            # Check if the column contains numerical data\n",
    "            if pd.api.types.is_numeric_dtype(first_10_rows[column]):\n",
    "                continue\n",
    "            else:\n",
    "                non_numerical_columns.append(column)\n",
    "\n",
    "        # Remove non-numerical columns from the dataframe\n",
    "        data = data.copy()\n",
    "        data.drop(columns=non_numerical_columns, inplace=True)\n",
    "        \n",
    "        # Print message with deleted columns\n",
    "        if self.verbose:\n",
    "            if non_numerical_columns:\n",
    "                print(\"Succesfully removed columns with non-numerical values:\", non_numerical_columns)\n",
    "      \n",
    "        return data\n",
    "    \n",
    "    def preprocess_data(self, data):\n",
    "        if type(data) != pd.DataFrame:\n",
    "            raise Exception('data must be a pandas dataframe')\n",
    "        \n",
    "        subset_data = self.subset_stock_data(data)\n",
    "        print(np.shape(subset_data))\n",
    "        subset_numerical_data = self.remove_non_numerical_columns(subset_data)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.fit_transform(subset_numerical_data) #TODO CHECK WEATHER WE PREFER OTHER TRANSFORMATION\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('Succesfully scaled data.')\n",
    "\n",
    "        return scaled_data\n",
    "    \n",
    "    def find_q(self):\n",
    "        explained_variance = self.explained_variance\n",
    "        cumulative_expl_var = [sum(explained_variance[:i+1]) for i in range(len(explained_variance))]\n",
    "        for i,j in enumerate(cumulative_expl_var):\n",
    "            if j >= self.explained_var:\n",
    "                self.q = i\n",
    "                break   \n",
    " \n",
    "    def fit_pca(self, X):\n",
    "        self.pca = PCA()\n",
    "        self.pca.fit(X)\n",
    "\n",
    "        self.principal_components = self.pca.components_\n",
    "        self.explained_variance = self.pca.explained_variance_ratio_\n",
    "        if self.q == None:\n",
    "            self.find_q()       \n",
    "\n",
    "    def fit_pfa(self, X):\n",
    "        q = self.q      \n",
    "        A_q = self.principal_components.T[:,:q]\n",
    "        \n",
    "        clusternumber = min([q + self.diff_n_features, X.shape[1]])\n",
    "        \n",
    "        kmeans = KMeans(n_clusters = clusternumber).fit(A_q)\n",
    "        clusters = kmeans.predict(A_q)\n",
    "        cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "        dists = defaultdict(list)\n",
    "        for i, c in enumerate(clusters):\n",
    "            dist = euclidean_distances([A_q[i, :]], [cluster_centers[c, :]])[0][0]\n",
    "            dists[c].append((i, dist))\n",
    "\n",
    "        self.indices = [sorted(f, key=lambda x: x[1])[0][0] for f in dists.values()]\n",
    "        self.features = X[:, self.indices]\n",
    "     \n",
    "    def fit(self, data, preprocess = True):\n",
    "        if preprocess:\n",
    "            scaled_data = self.preprocess_data(data)\n",
    "        else:\n",
    "            scaled_data = data\n",
    "\n",
    "        self.fit_pca(scaled_data)\n",
    "\n",
    "        if self.verbose:\n",
    "            print('Succesfully performed Principal Component Analysis')\n",
    "\n",
    "        if self.method == 'pfa':\n",
    "            self.fit_pfa(scaled_data)\n",
    "\n",
    "            if self.verbose:\n",
    "                print('Succesfully performed Principal Feature Analysis')\n",
    "\n",
    "        self.fitted = True\n",
    "\n",
    "    def transform(self, data, preprocess = True):\n",
    "        if preprocess:\n",
    "            scaled_data = self.preprocess_data(data)\n",
    "        else:\n",
    "            scaled_data = data\n",
    "\n",
    "        if self.fitted != True:\n",
    "            raise Exception('The model has not been fitted to the data.')\n",
    "        \n",
    "        if self.method == 'pca':\n",
    "            print('shape of scaled data: ', np.shape(scaled_data))\n",
    "            print('shape of transpose of principal components: ', np.shape(np.transpose(self.principal_components)))\n",
    "            self.reduced_data = np.matmul(np.array(scaled_data), np.transpose(self.principal_components))[:, :self.q]\n",
    "            print('shape of reduced data: ', np.shape(self.reduced_data))\n",
    "            return self.reduced_data\n",
    "        \n",
    "        elif self.method == 'pfa':\n",
    "            return self.features\n",
    "\n",
    "    def fit_transform(self, data):\n",
    "        scaled_data = self.preprocess_data(data)\n",
    "\n",
    "        self.fit(scaled_data)\n",
    "        output = self.transform(scaled_data)\n",
    "        return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
