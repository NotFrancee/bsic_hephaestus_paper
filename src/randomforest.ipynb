{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/filipporonzino/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "df = pd.read_csv('/Users/filipporonzino/Downloads/datasetlabel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['permno', 'CAPEI', 'bm', 'evm', 'pe_op_basic', 'pe_op_dil', 'pe_exi',\n",
       "       'pe_inc', 'ps', 'pcf', 'npm', 'opmbd', 'opmad', 'gpm', 'ptpm', 'cfm',\n",
       "       'roa', 'roe', 'roce', 'aftret_eq', 'aftret_invcapx', 'aftret_equity',\n",
       "       'GProf', 'equity_invcap', 'debt_invcap', 'totdebt_invcap',\n",
       "       'capital_ratio', 'cash_lt', 'debt_at', 'debt_ebitda', 'short_debt',\n",
       "       'lt_debt', 'cash_debt', 'fcf_ocf', 'lt_ppent', 'dltt_be', 'debt_assets',\n",
       "       'debt_capital', 'de_ratio', 'at_turn', 'rect_turn', 'pay_turn',\n",
       "       'sale_invcap', 'sale_equity', 'rd_sale', 'adv_sale', 'staff_sale',\n",
       "       'accrual', 'ptb', 'divyield', 'date', 'prc', 'vol', 'ret', 'retx',\n",
       "       'mktcap', 'prc_adj', 'naics_processed', 'ret_industry_tot',\n",
       "       'ret_industry_relative', 'MACD_index', 'rsi', 'stat_divyeld', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>CAPEI</th>\n",
       "      <th>bm</th>\n",
       "      <th>evm</th>\n",
       "      <th>pe_op_basic</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>pe_exi</th>\n",
       "      <th>pe_inc</th>\n",
       "      <th>ps</th>\n",
       "      <th>pcf</th>\n",
       "      <th>...</th>\n",
       "      <th>retx</th>\n",
       "      <th>mktcap</th>\n",
       "      <th>prc_adj</th>\n",
       "      <th>naics_processed</th>\n",
       "      <th>ret_industry_tot</th>\n",
       "      <th>ret_industry_relative</th>\n",
       "      <th>MACD_index</th>\n",
       "      <th>rsi</th>\n",
       "      <th>stat_divyeld</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>10078</td>\n",
       "      <td>-77.244</td>\n",
       "      <td>0.359771</td>\n",
       "      <td>69.237</td>\n",
       "      <td>-26.063</td>\n",
       "      <td>-26.063</td>\n",
       "      <td>-24.529</td>\n",
       "      <td>-24.529</td>\n",
       "      <td>0.679451</td>\n",
       "      <td>32.069082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018779</td>\n",
       "      <td>6.116791</td>\n",
       "      <td>7.107231</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.367858</td>\n",
       "      <td>0.187231</td>\n",
       "      <td>0.131991</td>\n",
       "      <td>64.582393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>10078</td>\n",
       "      <td>-77.244</td>\n",
       "      <td>0.359771</td>\n",
       "      <td>69.237</td>\n",
       "      <td>-26.063</td>\n",
       "      <td>-26.063</td>\n",
       "      <td>-24.529</td>\n",
       "      <td>-24.529</td>\n",
       "      <td>0.677843</td>\n",
       "      <td>32.069082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041475</td>\n",
       "      <td>6.137874</td>\n",
       "      <td>6.745006</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-0.497445</td>\n",
       "      <td>-0.726844</td>\n",
       "      <td>0.154507</td>\n",
       "      <td>46.918255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>10078</td>\n",
       "      <td>-77.244</td>\n",
       "      <td>0.359771</td>\n",
       "      <td>69.237</td>\n",
       "      <td>-26.063</td>\n",
       "      <td>-26.063</td>\n",
       "      <td>-24.529</td>\n",
       "      <td>-24.529</td>\n",
       "      <td>0.676476</td>\n",
       "      <td>32.069082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>6.090311</td>\n",
       "      <td>7.106134</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.573959</td>\n",
       "      <td>-0.431592</td>\n",
       "      <td>0.166956</td>\n",
       "      <td>48.716550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>10078</td>\n",
       "      <td>-77.244</td>\n",
       "      <td>0.359771</td>\n",
       "      <td>69.237</td>\n",
       "      <td>-26.063</td>\n",
       "      <td>-26.063</td>\n",
       "      <td>-24.529</td>\n",
       "      <td>-24.529</td>\n",
       "      <td>0.675291</td>\n",
       "      <td>32.069082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007177</td>\n",
       "      <td>6.105996</td>\n",
       "      <td>6.297823</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.041632</td>\n",
       "      <td>-0.254214</td>\n",
       "      <td>0.170147</td>\n",
       "      <td>46.018281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>10078</td>\n",
       "      <td>-77.244</td>\n",
       "      <td>0.359771</td>\n",
       "      <td>69.237</td>\n",
       "      <td>-26.063</td>\n",
       "      <td>-26.063</td>\n",
       "      <td>-24.529</td>\n",
       "      <td>-24.529</td>\n",
       "      <td>0.674249</td>\n",
       "      <td>32.069082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012048</td>\n",
       "      <td>6.100701</td>\n",
       "      <td>6.565685</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-0.281970</td>\n",
       "      <td>-0.074806</td>\n",
       "      <td>0.163791</td>\n",
       "      <td>41.588533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     permno   CAPEI        bm     evm  pe_op_basic  pe_op_dil  pe_exi  pe_inc  \\\n",
       "985   10078 -77.244  0.359771  69.237      -26.063    -26.063 -24.529 -24.529   \n",
       "986   10078 -77.244  0.359771  69.237      -26.063    -26.063 -24.529 -24.529   \n",
       "987   10078 -77.244  0.359771  69.237      -26.063    -26.063 -24.529 -24.529   \n",
       "988   10078 -77.244  0.359771  69.237      -26.063    -26.063 -24.529 -24.529   \n",
       "989   10078 -77.244  0.359771  69.237      -26.063    -26.063 -24.529 -24.529   \n",
       "\n",
       "           ps        pcf  ...      retx    mktcap   prc_adj  naics_processed  \\\n",
       "985  0.679451  32.069082  ...  0.018779  6.116791  7.107231             33.0   \n",
       "986  0.677843  32.069082  ... -0.041475  6.137874  6.745006             33.0   \n",
       "987  0.676476  32.069082  ...  0.004808  6.090311  7.106134             33.0   \n",
       "988  0.675291  32.069082  ... -0.007177  6.105996  6.297823             33.0   \n",
       "989  0.674249  32.069082  ... -0.012048  6.100701  6.565685             33.0   \n",
       "\n",
       "     ret_industry_tot  ret_industry_relative  MACD_index        rsi  \\\n",
       "985          0.367858               0.187231    0.131991  64.582393   \n",
       "986         -0.497445              -0.726844    0.154507  46.918255   \n",
       "987          0.573959              -0.431592    0.166956  48.716550   \n",
       "988          0.041632              -0.254214    0.170147  46.018281   \n",
       "989         -0.281970              -0.074806    0.163791  41.588533   \n",
       "\n",
       "     stat_divyeld  target  \n",
       "985           0.0    -1.0  \n",
       "986           0.0    -1.0  \n",
       "987           0.0    -1.0  \n",
       "988           0.0    -1.0  \n",
       "989           0.0    -1.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use just the part of the dataset bewtween 2010 and 2012\n",
    "# I have the date\n",
    "df['Year'] = pd.to_datetime(df['date']).dt.year\n",
    "df = df[(df['Year'] >= 2010) & (df['Year'] <= 2012)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>CAPEI</th>\n",
       "      <th>bm</th>\n",
       "      <th>evm</th>\n",
       "      <th>pe_op_basic</th>\n",
       "      <th>pe_op_dil</th>\n",
       "      <th>pe_exi</th>\n",
       "      <th>pe_inc</th>\n",
       "      <th>ps</th>\n",
       "      <th>pcf</th>\n",
       "      <th>...</th>\n",
       "      <th>mktcap</th>\n",
       "      <th>prc_adj</th>\n",
       "      <th>naics_processed</th>\n",
       "      <th>ret_industry_tot</th>\n",
       "      <th>ret_industry_relative</th>\n",
       "      <th>MACD_index</th>\n",
       "      <th>rsi</th>\n",
       "      <th>stat_divyeld</th>\n",
       "      <th>target</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>10104</td>\n",
       "      <td>29.013</td>\n",
       "      <td>0.090318</td>\n",
       "      <td>7.361477</td>\n",
       "      <td>21.33</td>\n",
       "      <td>21.518</td>\n",
       "      <td>22.099</td>\n",
       "      <td>22.099</td>\n",
       "      <td>5.35</td>\n",
       "      <td>14.044</td>\n",
       "      <td>...</td>\n",
       "      <td>8.271152</td>\n",
       "      <td>6.997259</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.630492</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.625508</td>\n",
       "      <td>67.517981</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>10104</td>\n",
       "      <td>29.013</td>\n",
       "      <td>0.090318</td>\n",
       "      <td>7.361477</td>\n",
       "      <td>21.33</td>\n",
       "      <td>21.518</td>\n",
       "      <td>22.099</td>\n",
       "      <td>22.099</td>\n",
       "      <td>5.35</td>\n",
       "      <td>14.044</td>\n",
       "      <td>...</td>\n",
       "      <td>8.287082</td>\n",
       "      <td>6.592372</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-0.007601</td>\n",
       "      <td>-0.050989</td>\n",
       "      <td>0.636078</td>\n",
       "      <td>66.308017</td>\n",
       "      <td>0.007850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>10104</td>\n",
       "      <td>29.013</td>\n",
       "      <td>0.090318</td>\n",
       "      <td>7.361477</td>\n",
       "      <td>21.33</td>\n",
       "      <td>21.518</td>\n",
       "      <td>22.099</td>\n",
       "      <td>22.099</td>\n",
       "      <td>5.35</td>\n",
       "      <td>14.044</td>\n",
       "      <td>...</td>\n",
       "      <td>8.283162</td>\n",
       "      <td>7.053588</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-0.586489</td>\n",
       "      <td>-0.117489</td>\n",
       "      <td>0.634516</td>\n",
       "      <td>53.125824</td>\n",
       "      <td>0.007824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>10104</td>\n",
       "      <td>29.013</td>\n",
       "      <td>0.090318</td>\n",
       "      <td>7.361477</td>\n",
       "      <td>21.33</td>\n",
       "      <td>21.518</td>\n",
       "      <td>22.099</td>\n",
       "      <td>22.099</td>\n",
       "      <td>5.35</td>\n",
       "      <td>14.044</td>\n",
       "      <td>...</td>\n",
       "      <td>8.267549</td>\n",
       "      <td>6.924452</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-0.344716</td>\n",
       "      <td>0.184659</td>\n",
       "      <td>0.622710</td>\n",
       "      <td>50.549086</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>10104</td>\n",
       "      <td>29.013</td>\n",
       "      <td>0.090318</td>\n",
       "      <td>7.361477</td>\n",
       "      <td>21.33</td>\n",
       "      <td>21.518</td>\n",
       "      <td>22.099</td>\n",
       "      <td>22.099</td>\n",
       "      <td>5.35</td>\n",
       "      <td>14.044</td>\n",
       "      <td>...</td>\n",
       "      <td>8.267643</td>\n",
       "      <td>6.544365</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.161365</td>\n",
       "      <td>0.440445</td>\n",
       "      <td>0.608468</td>\n",
       "      <td>59.126978</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      permno   CAPEI        bm       evm  pe_op_basic  pe_op_dil  pe_exi  \\\n",
       "4795   10104  29.013  0.090318  7.361477        21.33     21.518  22.099   \n",
       "4796   10104  29.013  0.090318  7.361477        21.33     21.518  22.099   \n",
       "4797   10104  29.013  0.090318  7.361477        21.33     21.518  22.099   \n",
       "4798   10104  29.013  0.090318  7.361477        21.33     21.518  22.099   \n",
       "4799   10104  29.013  0.090318  7.361477        21.33     21.518  22.099   \n",
       "\n",
       "      pe_inc    ps     pcf  ...    mktcap   prc_adj  naics_processed  \\\n",
       "4795  22.099  5.35  14.044  ...  8.271152  6.997259             51.0   \n",
       "4796  22.099  5.35  14.044  ...  8.287082  6.592372             51.0   \n",
       "4797  22.099  5.35  14.044  ...  8.283162  7.053588             51.0   \n",
       "4798  22.099  5.35  14.044  ...  8.267549  6.924452             51.0   \n",
       "4799  22.099  5.35  14.044  ...  8.267643  6.544365             51.0   \n",
       "\n",
       "      ret_industry_tot  ret_industry_relative  MACD_index        rsi  \\\n",
       "4795          0.630492               0.001711    0.625508  67.517981   \n",
       "4796         -0.007601              -0.050989    0.636078  66.308017   \n",
       "4797         -0.586489              -0.117489    0.634516  53.125824   \n",
       "4798         -0.344716               0.184659    0.622710  50.549086   \n",
       "4799          0.161365               0.440445    0.608468  59.126978   \n",
       "\n",
       "      stat_divyeld  target  Year  \n",
       "4795      0.007330     1.0  2010  \n",
       "4796      0.007850     1.0  2010  \n",
       "4797      0.007824     1.0  2010  \n",
       "4798      0.007812     1.0  2010  \n",
       "4799      0.007804     1.0  2010  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18775 11127]\n",
      " [ 8119 38076]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.70      0.63      0.66     29902\n",
      "         1.0       0.77      0.82      0.80     46195\n",
      "\n",
      "    accuracy                           0.75     76097\n",
      "   macro avg       0.74      0.73      0.73     76097\n",
      "weighted avg       0.74      0.75      0.74     76097\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m roc_auc_score(y_test, y_pred_proba)\n\u001b[1;32m     26\u001b[0m \u001b[39m# Learning Curve\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m train_sizes, train_scores, test_scores \u001b[39m=\u001b[39m learning_curve(RandomForestClassifier(n_estimators \u001b[39m=\u001b[39;49m \u001b[39m30\u001b[39;49m, criterion \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mentropy\u001b[39;49m\u001b[39m'\u001b[39;49m, random_state \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m), X, y, cv\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m, train_sizes\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mlinspace(\u001b[39m0.01\u001b[39;49m, \u001b[39m1.0\u001b[39;49m, \u001b[39m50\u001b[39;49m))\n\u001b[1;32m     28\u001b[0m train_mean \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(train_scores, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m train_std \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstd(train_scores, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:1686\u001b[0m, in \u001b[0;36mlearning_curve\u001b[0;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times, fit_params)\u001b[0m\n\u001b[1;32m   1683\u001b[0m     \u001b[39mfor\u001b[39;00m n_train_samples \u001b[39min\u001b[39;00m train_sizes_abs:\n\u001b[1;32m   1684\u001b[0m         train_test_proportions\u001b[39m.\u001b[39mappend((train[:n_train_samples], test))\n\u001b[0;32m-> 1686\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m   1687\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m   1688\u001b[0m         clone(estimator),\n\u001b[1;32m   1689\u001b[0m         X,\n\u001b[1;32m   1690\u001b[0m         y,\n\u001b[1;32m   1691\u001b[0m         scorer,\n\u001b[1;32m   1692\u001b[0m         train,\n\u001b[1;32m   1693\u001b[0m         test,\n\u001b[1;32m   1694\u001b[0m         verbose,\n\u001b[1;32m   1695\u001b[0m         parameters\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1696\u001b[0m         fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m   1697\u001b[0m         return_train_score\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1698\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m   1699\u001b[0m         return_times\u001b[39m=\u001b[39;49mreturn_times,\n\u001b[1;32m   1700\u001b[0m     )\n\u001b[1;32m   1701\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m train_test_proportions\n\u001b[1;32m   1702\u001b[0m )\n\u001b[1;32m   1703\u001b[0m results \u001b[39m=\u001b[39m _aggregate_score_dicts(results)\n\u001b[1;32m   1704\u001b[0m train_scores \u001b[39m=\u001b[39m results[\u001b[39m\"\u001b[39m\u001b[39mtrain_scores\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, n_unique_ticks)\u001b[39m.\u001b[39mT\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    730\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    731\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    734\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    460\u001b[0m )(\n\u001b[1;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    462\u001b[0m         t,\n\u001b[1;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    464\u001b[0m         X,\n\u001b[1;32m    465\u001b[0m         y,\n\u001b[1;32m    466\u001b[0m         sample_weight,\n\u001b[1;32m    467\u001b[0m         i,\n\u001b[1;32m    468\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    472\u001b[0m     )\n\u001b[1;32m    473\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    474\u001b[0m )\n\u001b[1;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 188\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    929\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    930\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \n\u001b[1;32m    932\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m    960\u001b[0m         X,\n\u001b[1;32m    961\u001b[0m         y,\n\u001b[1;32m    962\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    963\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    964\u001b[0m     )\n\u001b[1;32m    965\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Selecting the features and the target\n",
    "X = df[['MACD_index', 'rsi',  'mktcap', 'vol', 'ret_industry_tot']]\n",
    "y = df['target']\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "# Random Forest Classifier\n",
    "classifier = RandomForestClassifier(n_estimators = 30, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Making the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))\n",
    "# ROC Curve\n",
    "y_pred_proba = classifier.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr, label='Random Forest')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('Random Forest ROC curve')\n",
    "plt.show()\n",
    "# AUC\n",
    "roc_auc_score(y_test, y_pred_proba)\n",
    "# Learning Curve\n",
    "train_sizes, train_scores, test_scores = learning_curve(RandomForestClassifier(n_estimators = 30, criterion = 'entropy', random_state = 0), X, y, cv=10, scoring='accuracy', train_sizes=np.linspace(0.01, 1.0, 50))\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "plt.plot(train_sizes, train_mean, label='train accuracy')\n",
    "plt.plot(train_sizes, test_mean, label='test accuracy')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='#DDDDDD')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color='#DDDDDD')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m param_grid \u001b[39m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m40\u001b[39m, \u001b[39m60\u001b[39m, \u001b[39m70\u001b[39m],\n\u001b[1;32m      5\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmax_features\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.6\u001b[39m, \u001b[39m0.7\u001b[39m, \u001b[39m0.8\u001b[39m]\n\u001b[1;32m      6\u001b[0m }\n\u001b[1;32m      7\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(estimator \u001b[39m=\u001b[39m random_forest, param_grid \u001b[39m=\u001b[39m param_grid, cv \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      9\u001b[0m grid_search\u001b[39m.\u001b[39mbest_params_\n\u001b[1;32m     10\u001b[0m grid_search\u001b[39m.\u001b[39mbest_score_\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    730\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    731\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    734\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    735\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    736\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    460\u001b[0m )(\n\u001b[1;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    462\u001b[0m         t,\n\u001b[1;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    464\u001b[0m         X,\n\u001b[1;32m    465\u001b[0m         y,\n\u001b[1;32m    466\u001b[0m         sample_weight,\n\u001b[1;32m    467\u001b[0m         i,\n\u001b[1;32m    468\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    472\u001b[0m     )\n\u001b[1;32m    473\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    474\u001b[0m )\n\u001b[1;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 188\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    929\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    930\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \n\u001b[1;32m    932\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m    960\u001b[0m         X,\n\u001b[1;32m    961\u001b[0m         y,\n\u001b[1;32m    962\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    963\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    964\u001b[0m     )\n\u001b[1;32m    965\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Grid search for hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [40, 60, 70],\n",
    "    'max_features': [0.6, 0.7, 0.8]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator = random_forest, param_grid = param_grid, cv = 5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_\n",
    "grid_search.best_score_\n",
    "# Predicting the Test set results\n",
    "y_pred = grid_search.predict(X_test)\n",
    "# Check accuracy score\n",
    "accuracy_score(y_test, y_pred)\n",
    "# Confusion matrix\n",
    "confusion_matrix(y_test, y_pred)\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "# ROC AUC score\n",
    "roc_auc_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.87      0.87      0.87     35555\n",
      "         1.0       0.88      0.88      0.88     39347\n",
      "\n",
      "    accuracy                           0.88     74902\n",
      "   macro avg       0.88      0.88      0.88     74902\n",
      "weighted avg       0.88      0.88      0.88     74902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset according to the years 2008-2010, 2010-2012, 2012-2014, 2014-2016, 2016-2018\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "df['year'].unique()\n",
    "df_2008_2010 = df[(df['year'] >= 2008) & (df['year'] <= 2010)]\n",
    "df_2010_2012 = df[(df['year'] >= 2010) & (df['year'] <= 2012)]\n",
    "df_2012_2014 = df[(df['year'] >= 2012) & (df['year'] <= 2014)]\n",
    "df_2014_2016 = df[(df['year'] >= 2014) & (df['year'] <= 2016)]\n",
    "df_2016_2018 = df[(df['year'] >= 2016) & (df['year'] <= 2018)]\n",
    "# Selecting the features and the target\n",
    "X_2008_2010 = df_2008_2010[['CAPEI', 'bm', 'evm', 'pe_op_basic', 'pe_op_dil', 'pe_exi',\n",
    "       'pe_inc', 'ps', 'pcf', 'npm', 'opmbd', 'opmad', 'gpm', 'ptpm', 'cfm',\n",
    "       'roa', 'roe', 'roce', 'aftret_eq', 'aftret_invcapx', 'aftret_equity',\n",
    "       'GProf', 'equity_invcap', 'debt_invcap', 'totdebt_invcap',\n",
    "       'capital_ratio', 'cash_lt', 'debt_at', 'debt_ebitda', 'short_debt',\n",
    "       'lt_debt', 'cash_debt', 'fcf_ocf', 'lt_ppent']]\n",
    "y_2008_2010 = df_2008_2010['target']\n",
    "X_2010_2012 = df_2010_2012[['MACD_index', 'rsi',  'mktcap', 'vol', 'ret_industry_tot']]\n",
    "y_2010_2012 = df_2010_2012['target']\n",
    "X_2012_2014 = df_2012_2014[['MACD_index', 'rsi',  'mktcap', 'vol', 'ret_industry_tot']]\n",
    "y_2012_2014 = df_2012_2014['target']\n",
    "X_2014_2016 = df_2014_2016[['MACD_index', 'rsi',  'mktcap', 'vol', 'ret_industry_tot']]\n",
    "y_2014_2016 = df_2014_2016['target']\n",
    "X_2016_2018 = df_2016_2018[['MACD_index', 'rsi',  'mktcap', 'vol', 'ret_industry_tot']]\n",
    "y_2016_2018 = df_2016_2018['target']\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train_2008_2010, X_test_2008_2010, y_train_2008_2010, y_test_2008_2010 = train_test_split(X_2008_2010, y_2008_2010, test_size = 0.2, random_state = 42)\n",
    "X_train_2010_2012, X_test_2010_2012, y_train_2010_2012, y_test_2010_2012 = train_test_split(X_2010_2012, y_2010_2012, test_size = 0.2, random_state = 42)\n",
    "X_train_2012_2014, X_test_2012_2014, y_train_2012_2014, y_test_2012_2014 = train_test_split(X_2012_2014, y_2012_2014, test_size = 0.2, random_state = 42)\n",
    "X_train_2014_2016, X_test_2014_2016, y_train_2014_2016, y_test_2014_2016 = train_test_split(X_2014_2016, y_2014_2016, test_size = 0.2, random_state = 42)\n",
    "X_train_2016_2018, X_test_2016_2018, y_train_2016_2018, y_test_2016_2018 = train_test_split(X_2016_2018, y_2016_2018, test_size = 0.2, random_state = 42)\n",
    "# Create Random Forest object\n",
    "random_forest = RandomForestClassifier(n_estimators = 20, max_features = 3, random_state = 42, bootstrap=True)\n",
    "# Train model\n",
    "random_forest.fit(X_train_2008_2010, y_train_2008_2010)\n",
    "# Predicting the Test set results\n",
    "y_pred_2008_2010 = random_forest.predict(X_test_2008_2010)\n",
    "# Check accuracy score\n",
    "accuracy_score(y_test_2008_2010, y_pred_2008_2010)\n",
    "# Confusion matrix\n",
    "confusion_matrix(y_test_2008_2010, y_pred_2008_2010)\n",
    "# Classification report\n",
    "print(classification_report(y_test_2008_2010, y_pred_2008_2010))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 | packaged by conda-forge | (main, Jan 14 2023, 12:25:12) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f217336c97d15ce4a94207d0500046615b0bc55fbf2d342e9c35c59defb6831"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
