{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fractional_differentiation import find_stat_series\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import itertools\n",
    "import multiprocess as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading fundamentals for divyield\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funds = pd.read_csv(\"../../data/fundamentals_clean.csv\", parse_dates=[\"public_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_divyield(x):\n",
    "    if x == \"0\":\n",
    "        return 0\n",
    "    elif x[-1] == \"%\":\n",
    "        return float(x[:-1]) / 100\n",
    "    else:\n",
    "        raise ValueError(f\"unexpected value {x}\")\n",
    "\n",
    "\n",
    "funds[\"divyield\"] = funds[\"divyield\"].apply(process_divyield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divyield = funds.set_index([\"permno\", \"public_date\"])[\"divyield\"]\n",
    "\n",
    "divyield.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = pd.read_csv(\"../../data/merged_fin.csv\", parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.dropna(subset=\"date\", inplace=True)\n",
    "prices.sort_values(by=[\"permno\", \"date\"], inplace=True)\n",
    "\n",
    "prices.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices[\"mktcap\"] = prices[\"mktcap\"].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divyield = divyield.reindex(\n",
    "    prices[[\"permno\", \"date\"]].set_index([\"permno\", \"date\"]).index\n",
    ").ffill()\n",
    "\n",
    "divyield.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices[\"divyield\"] = divyield.values\n",
    "\n",
    "prices[\"divyield\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redundant = [\"pe_op_basic\", \"pe_exi\", \"prc\", \"retx\"]\n",
    "prices.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Stationary Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_features = [\"naics_processed\", \"permno\", \"date\", \"vol\"]\n",
    "features = prices.columns.drop(exclude_features)\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permnos = prices[\"permno\"].unique()\n",
    "prices_stat = prices.copy()\n",
    "\n",
    "diffs = np.linspace(0.05, 1.95, 39)\n",
    "\n",
    "len(permnos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "# just to display progress\n",
    "f = IntProgress(min=0, max=np.prod([len(features), len(permnos)]))\n",
    "display(f)\n",
    "\n",
    "# iterate through all permnos and features\n",
    "for permno, feature in itertools.product(permnos, features):\n",
    "    f.value += 1\n",
    "\n",
    "    # select the data relative to the permno and feature\n",
    "    mask = prices[\"permno\"] == permno\n",
    "    data = prices.loc[mask, [feature]]\n",
    "    original_index = data.index\n",
    "    data = data.dropna()\n",
    "\n",
    "    # handle features which are empty\n",
    "    if data.empty:\n",
    "        print(f\"there is no data for {permno} - {feature}\")\n",
    "        continue\n",
    "\n",
    "    if np.max(data) - np.min(data) < 1e-6:\n",
    "        print(f\"there is no variation in {permno} - {feature}\")\n",
    "        continue\n",
    "\n",
    "    print(permno, feature)\n",
    "    print(\"-----\")\n",
    "    # check if the series is stationary\n",
    "    try:\n",
    "        if adfuller(data, regression=\"ct\")[1] > 0.01:\n",
    "            stat_series = find_stat_series(data, diffs=diffs)\n",
    "            stat_series = stat_series.reindex(original_index)\n",
    "            prices_stat.loc[mask, feature] = stat_series.values\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"error in {permno} - {feature}\")\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_stat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_stat.to_csv(\"../../data/DATA_STATIONARY.zip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_stat.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_stat.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/DATA_STATIONARY.zip')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Non-Stationary Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15401 aftret_invcapx\n",
    "\n",
    "\n",
    "mask = prices[\"permno\"] == 15401\n",
    "\n",
    "prices.loc[mask].plot(x=\"date\", y=\"aftret_invcapx\")\n",
    "\n",
    "\n",
    "# prices.loc[mask, \"ticker\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    find_stat_series(\n",
    "        prices.loc[mask, [\"aftret_invcapx\"]], diffs=np.linspace(0.05, 2.95, 39)\n",
    "    ).plot()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelizing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series().empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(permnos: np.ndarray) -> dict[int, dict[str, bool]]:\n",
    "    print(f\"processing {permnos}\", flush=True)\n",
    "    is_stationary: dict[int, dict[str, bool]] = {}\n",
    "\n",
    "    for permno, feature in itertools.product(permnos, features):\n",
    "        # select the data relative to the permno and feature\n",
    "        is_stationary[permno] = {}\n",
    "        mask = prices[\"permno\"] == permno\n",
    "        data = prices[mask][feature].dropna()\n",
    "\n",
    "        # handle features which are empty\n",
    "        if data.empty:\n",
    "            print(f\"there is no data for {permno} - {feature}\")\n",
    "            is_stationary[permno][feature] = True\n",
    "            continue\n",
    "\n",
    "        # check if the series is stationary\n",
    "        if adfuller(data, regression=\"ct\")[1] > 0.01:\n",
    "            is_stationary[permno][feature] = False\n",
    "        else:\n",
    "            is_stationary[permno][feature] = True\n",
    "\n",
    "    return is_stationary\n",
    "\n",
    "\n",
    "def process_permno(permno: int):\n",
    "    print(f\"processing {permno}\", flush=True)\n",
    "    res = {}\n",
    "    for feature in features:\n",
    "\n",
    "        mask = prices[\"permno\"] == permno\n",
    "        data = prices[mask][feature].dropna()\n",
    "\n",
    "        # handle features which are empty\n",
    "        if data.empty:\n",
    "            print(f\"there is no data for {permno} - {feature}\")\n",
    "            res[feature] = True\n",
    "\n",
    "        # check if the series is stationary\n",
    "        if adfuller(data, regression=\"ct\")[1] > 0.01:\n",
    "            res[feature] = False\n",
    "        else:\n",
    "            res[feature] = True\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def store_results(res: list[dict[int, dict[str, bool]]]):\n",
    "    for item in res:\n",
    "        results.update(item)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results: dict[int, dict[str, bool]] = {}\n",
    "\n",
    "    ncpus = mp.cpu_count() - 1\n",
    "\n",
    "    with mp.Pool(ncpus) as p:\n",
    "        # res = p.map(process_permno, np.array(non_stat.index), chunksize=100)\n",
    "        res = p.map_async(\n",
    "            process_data,\n",
    "            np.array_split(np.array(non_stat.index), ncpus),\n",
    "            chunksize=100,\n",
    "        )\n",
    "        res.get()\n",
    "\n",
    "        # for permnos in np.array_split(np.array(non_stat.index), ncpus):\n",
    "        #     res = p.apply(process_data, args=(permnos,))\n",
    "        #     print(res)\n",
    "\n",
    "    p.join()\n",
    "\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import os\n",
    "\n",
    "\n",
    "def f(r):\n",
    "    import numpy as np\n",
    "    import os\n",
    "    from time import sleep\n",
    "\n",
    "    res = np.arange(r[0], r[1])\n",
    "    print(f\"I am {os.getpid()}\")\n",
    "    sleep(10)\n",
    "    print(f\"I am {os.getpid()} and I am finished\")\n",
    "    return {\"nums\": res, \"dubs\": res * 2}\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     ctx = mp.get_context(\"spawn\")\n",
    "#     with ctx.Pool(4) as p:\n",
    "#         subsets = [[0, 3], [3, 6], [6, 7]]\n",
    "#         res = p.map(f, subsets)\n",
    "#         print(res)\n",
    "\n",
    "#     print(\"Done!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with mp.Pool(4) as p:\n",
    "        res = p.map(f, subsets)\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final: dict[int, dict[str, bool]] = {}\n",
    "\n",
    "\n",
    "def process_data(permnos: np.ndarray):\n",
    "    import os\n",
    "\n",
    "    print(f\"initiating process {os.getpid()} - first permno {permnos[0]}\\n\")\n",
    "\n",
    "    # stores permno and stationarity for each feature\n",
    "    is_stationary: dict[int, dict[str, bool]] = {permno: {} for permno in permnos}\n",
    "\n",
    "    # iterate through each permno and feature\n",
    "    for permno in permnos:\n",
    "        mask = prices[\"permno\"] == permno\n",
    "        permno_data = prices[mask]\n",
    "\n",
    "        for feature in features:\n",
    "            feature_data = permno_data[feature].dropna()\n",
    "\n",
    "            if feature_data.empty:\n",
    "                print(f\"there is no data for {permno} - {feature}\")\n",
    "                is_stationary[permno][feature] = True\n",
    "                continue\n",
    "\n",
    "            if adfuller(feature_data, regression=\"ct\")[1] > 0.01:\n",
    "                is_stationary[permno][feature] = False\n",
    "            else:\n",
    "                is_stationary[permno][feature] = True\n",
    "\n",
    "    return is_stationary\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ncpus = mp.cpu_count() - 1\n",
    "    print(f\"running with {ncpus} cpus\")\n",
    "\n",
    "    with mp.Pool(ncpus) as p:\n",
    "        permnos_split = np.array_split(np.array(non_stat.index), ncpus)\n",
    "\n",
    "        res: list[dict[int, dict[str, bool]]] = p.map(process_data, permnos_split)\n",
    "\n",
    "        if not isinstance(res, list):\n",
    "            raise Exception(\"res is not a list\")\n",
    "\n",
    "        for item in res:\n",
    "            final.update(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing Stationarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
