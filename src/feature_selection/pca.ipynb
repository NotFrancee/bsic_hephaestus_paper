{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Selection:\n",
    "    def __init__(self, start_date, end_date, method='pfa', verbose=False):\n",
    "        #TODO check start date and end date are in date format\n",
    "        if method not in ['pca', 'pfa']:\n",
    "            raise Exception('Method must be either PCA or PFA')\n",
    "        #TODO check there is data for each stock in the selected period\n",
    "\n",
    "        self.method = method\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        \n",
    "        #For pfa\n",
    "        self.pfa_features = None\n",
    "        \n",
    "        #For pca\n",
    "        self.principal_components = None\n",
    "        self.explained_variance_ratio = None\n",
    "\n",
    "\n",
    "    def fit(self, data):\n",
    "        if type(data) != pd.DataFrame:\n",
    "            raise Exception('data must be a pandas dataframe')\n",
    "        \n",
    "        subset_data = self.subset_stock_data(data)\n",
    "    \n",
    "        subset_numerical_data = self.subset_stock_data(subset_data)\n",
    "        scaler = StandardScaler()\n",
    "        scaled_data = scaler.transform(subset_numerical_data) #TODO CHECK WEATHER WE PREFER OTHER TRANSFORMATION\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('Succesfully scaled data.')\n",
    "        \n",
    "        if self.method == 'pfa':\n",
    "            self.run_pca(scaled_data)\n",
    "        \n",
    "        elif self.method == 'pca':\n",
    "            self.pfa_features = self.run_pfa(scaled_data)\n",
    "\n",
    "    def subset_stock_data(self, data):\n",
    "        # Check if 'Date' column exists in the dataframe\n",
    "        if 'Date' not in self.data.columns:\n",
    "            raise ValueError(\"DataFrame does not contain a 'Date' column.\")\n",
    "        \n",
    "        # Convert date columns to datetime if they are not already datetime objects\n",
    "        if not isinstance(self.data['Date'], pd.DatetimeIndex):\n",
    "            self.data['Date'] = pd.to_datetime(self.data['Date'])\n",
    "        \n",
    "        # Subset the dataframe based on date range\n",
    "        subset = data[(data['Date'] >= self.start_date) & (data['Date'] <= self.end_date)]\n",
    "        if self.verbose:\n",
    "            print('Succesfully subsetted data for selected timeframe.')\n",
    "        return subset\n",
    "    \n",
    "    def remove_non_numerical_columns(self, data):\n",
    "        # Check first 10 rows for numerical columns\n",
    "        first_10_rows = data.head(10)\n",
    "        non_numerical_columns = []\n",
    "\n",
    "        # Iterate through columns\n",
    "        for column in data.columns:\n",
    "            # Check if the column contains numerical data\n",
    "            if pd.api.types.is_numeric_dtype(first_10_rows[column]):\n",
    "                continue\n",
    "            else:\n",
    "                non_numerical_columns.append(column)\n",
    "\n",
    "        # Remove non-numerical columns from the dataframe\n",
    "        data.drop(columns=non_numerical_columns, inplace=True)\n",
    "        \n",
    "        # Print message with deleted columns\n",
    "        if self.verbose:\n",
    "            if non_numerical_columns:\n",
    "                print(\"Columns with non-numerical values removed:\", non_numerical_columns)\n",
    "            else:\n",
    "                print(\"No columns with non-numerical values found.\")\n",
    "        return data\n",
    "    \n",
    "    def run_pca(self, data):\n",
    "        pca = PCA()\n",
    "        self.principal_components = pca.fit_transform(data)\n",
    "        self.explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "    def run_pfa(self, df):\n",
    "        #TODO\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
